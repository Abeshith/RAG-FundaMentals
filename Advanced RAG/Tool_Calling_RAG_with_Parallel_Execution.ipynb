{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mulTiViHeIWd"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-groq langchain-huggingface langchain-chroma langchain-community langchain_tavily\n",
        "!pip install -q chromadb sentence-transformers requests wikipedia-api python-dotenv wikipedia\n",
        "!pip install -qU beautifulsoup4 requests chromadb arxiv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "id": "cTUSZxMyiuhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SmJ9994GhwpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from typing import TypedDict, Annotated, List, Dict, Any\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time"
      ],
      "metadata": {
        "id": "bP4ouhj8iouo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langchain_core.tools import tool, StructuredTool\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
        "from langchain_tavily import TavilySearch"
      ],
      "metadata": {
        "id": "wOmt03RYipqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode"
      ],
      "metadata": {
        "id": "rDrW-cGCitdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "uh2U7OKifBgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=2048\n",
        ")"
      ],
      "metadata": {
        "id": "a7DHbU9rfmNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")"
      ],
      "metadata": {
        "id": "QV2xxhKdfu_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma(\n",
        "    collection_name=\"parallel_rag\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")"
      ],
      "metadata": {
        "id": "J3EYplQgkGrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def web_search_tool(query: str) -> str:\n",
        "    \"\"\"Search the web for current information using Tavily.\"\"\"\n",
        "    tavily_search = TavilySearch(\n",
        "        max_results=3,\n",
        "        topic=\"general\",\n",
        "        include_raw_content=True,\n",
        "        search_depth=\"advanced\"\n",
        "    )\n",
        "    results = tavily_search.invoke({\"query\": query})\n",
        "\n",
        "    formatted_results = []\n",
        "    for result in results.get('results', []):\n",
        "        formatted_results.append(f\"Title: {result['title']}\\nURL: {result['url']}\\nContent: {result['content'][:500]}...\")\n",
        "\n",
        "    return \"\\n\\n\".join(formatted_results)"
      ],
      "metadata": {
        "id": "y8MSAc3RkITv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def wikipedia_search_tool(query: str) -> str:\n",
        "    \"\"\"Search Wikipedia for encyclopedic information.\"\"\"\n",
        "    wikipedia = WikipediaQueryRun(\n",
        "        api_wrapper=WikipediaAPIWrapper(\n",
        "            top_k_results=2,\n",
        "            doc_content_chars_max=1000\n",
        "        )\n",
        "    )\n",
        "    return wikipedia.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "Q87C5F9NkbST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def arxiv_search_tool(query: str) -> str:\n",
        "    \"\"\"Search arXiv for academic papers and research.\"\"\"\n",
        "    arxiv = ArxivQueryRun(\n",
        "        api_wrapper=ArxivAPIWrapper(\n",
        "            top_k_results=2,\n",
        "            doc_content_chars_max=1000\n",
        "        )\n",
        "    )\n",
        "    return arxiv.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "do8yQDuVkd3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def vector_search_tool(query: str) -> str:\n",
        "    \"\"\"Search the vector database for relevant documents.\"\"\"\n",
        "    if vectorstore._collection.count() == 0:\n",
        "        return \"Vector database is empty. Please load documents first.\"\n",
        "\n",
        "    docs = vectorstore.similarity_search(query, k=3)\n",
        "    results = []\n",
        "    for doc in docs:\n",
        "        results.append(f\"Content: {doc.page_content[:500]}...\")\n",
        "    return \"\\n\\n\".join(results)"
      ],
      "metadata": {
        "id": "z5kyQp4jkyXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def document_loader_tool(url: str) -> str:\n",
        "    \"\"\"Load and process documents from web URLs.\"\"\"\n",
        "    try:\n",
        "        loader = WebBaseLoader([url])\n",
        "        docs = loader.load()\n",
        "\n",
        "        # Add to vector store\n",
        "        vectorstore.add_documents(docs)\n",
        "\n",
        "        return f\"Successfully loaded {len(docs)} documents from {url}. Added to vector database.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error loading document from {url}: {str(e)}\""
      ],
      "metadata": {
        "id": "r0x1CDo9k0qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParallelRAGState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    query: str\n",
        "    tool_calls: List[Dict[str, Any]]\n",
        "    tool_results: Dict[str, Any]\n",
        "    parallel_results: Dict[str, Any]\n",
        "    final_context: str\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "nS0YgjN2k2Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_and_select_tools(query: str) -> List[str]:\n",
        "    \"\"\"Intelligently route query to appropriate tools based on content.\"\"\"\n",
        "    query_lower = query.lower()\n",
        "    selected_tools = []\n",
        "\n",
        "    # Always include vector search if we have documents\n",
        "    if vectorstore._collection.count() > 0:\n",
        "        selected_tools.append(\"vector_search_tool\")\n",
        "\n",
        "    # Add web search for current information\n",
        "    if any(keyword in query_lower for keyword in [\"latest\", \"recent\", \"current\", \"news\", \"2024\", \"2025\"]):\n",
        "        selected_tools.append(\"web_search_tool\")\n",
        "\n",
        "    # Add Wikipedia for general knowledge\n",
        "    if any(keyword in query_lower for keyword in [\"what is\", \"who is\", \"definition\", \"history\", \"concept\"]):\n",
        "        selected_tools.append(\"wikipedia_search_tool\")\n",
        "\n",
        "    # Add arXiv for research topics\n",
        "    if any(keyword in query_lower for keyword in [\"research\", \"study\", \"algorithm\", \"machine learning\", \"AI\", \"paper\"]):\n",
        "        selected_tools.append(\"arxiv_search_tool\")\n",
        "\n",
        "    # Ensure at least web search and wikipedia\n",
        "    if not selected_tools:\n",
        "        selected_tools = [\"web_search_tool\", \"wikipedia_search_tool\"]\n",
        "\n",
        "    return selected_tools"
      ],
      "metadata": {
        "id": "i5BpwxbUk64r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_tools_in_parallel(tools_to_execute: List[str], query: str) -> Dict[str, Any]:\n",
        "    \"\"\"Execute multiple tools in parallel using ThreadPoolExecutor.\"\"\"\n",
        "    tool_map = {\n",
        "        \"web_search_tool\": web_search_tool,\n",
        "        \"wikipedia_search_tool\": wikipedia_search_tool,\n",
        "        \"arxiv_search_tool\": arxiv_search_tool,\n",
        "        \"vector_search_tool\": vector_search_tool\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    start_time = time.time()\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=len(tools_to_execute)) as executor:\n",
        "        # Submit all tool executions\n",
        "        future_to_tool = {\n",
        "            executor.submit(tool_map[tool_name].invoke, {\"query\": query}): tool_name\n",
        "            for tool_name in tools_to_execute if tool_name in tool_map\n",
        "        }\n",
        "\n",
        "        # Collect results as they complete\n",
        "        for future in as_completed(future_to_tool):\n",
        "            tool_name = future_to_tool[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                results[tool_name] = result\n",
        "                print(f\"âœ“ {tool_name} completed in {time.time() - start_time:.2f}s\")\n",
        "            except Exception as e:\n",
        "                results[tool_name] = f\"Error: {str(e)}\"\n",
        "                print(f\"âœ— {tool_name} failed: {str(e)}\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nğŸ¯ Parallel execution completed in {total_time:.2f}s\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "G1hLpTZlk8vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_analysis_node(state: ParallelRAGState):\n",
        "    \"\"\"Analyze the query and determine which tools to use.\"\"\"\n",
        "    query = state[\"messages\"][-1].content if state[\"messages\"] else state.get(\"query\", \"\")\n",
        "\n",
        "    # Route to appropriate tools\n",
        "    selected_tools = route_and_select_tools(query)\n",
        "\n",
        "    print(f\"ğŸ” Query: {query}\")\n",
        "    print(f\"ğŸ› ï¸  Selected tools: {', '.join(selected_tools)}\")\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"tool_calls\": [{\"tool\": tool, \"query\": query} for tool in selected_tools]\n",
        "    }"
      ],
      "metadata": {
        "id": "q9Ct5x1gk_Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_tool_execution_node(state: ParallelRAGState):\n",
        "    \"\"\"Execute tools in parallel and collect results.\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    tool_calls = state[\"tool_calls\"]\n",
        "\n",
        "    # Extract tool names\n",
        "    tools_to_execute = [call[\"tool\"] for call in tool_calls]\n",
        "\n",
        "    print(f\"âš¡ Executing {len(tools_to_execute)} tools in parallel...\")\n",
        "\n",
        "    # Execute tools in parallel\n",
        "    parallel_results = execute_tools_in_parallel(tools_to_execute, query)\n",
        "\n",
        "    return {\n",
        "        \"parallel_results\": parallel_results,\n",
        "        \"tool_results\": parallel_results\n",
        "    }"
      ],
      "metadata": {
        "id": "eS32JX-slAqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def result_fusion_node(state: ParallelRAGState):\n",
        "    \"\"\"Fuse and rank results from parallel tool execution.\"\"\"\n",
        "    parallel_results = state[\"parallel_results\"]\n",
        "    query = state[\"query\"]\n",
        "\n",
        "    # Combine and weight results\n",
        "    combined_context = []\n",
        "\n",
        "    for tool_name, result in parallel_results.items():\n",
        "        if result and not result.startswith(\"Error\"):\n",
        "            # Add source attribution\n",
        "            combined_context.append(f\"=== {tool_name.upper().replace('_', ' ')} ===\\n{result}\\n\")\n",
        "\n",
        "    # Create final context\n",
        "    final_context = \"\\n\".join(combined_context)\n",
        "\n",
        "    print(f\"ğŸ“Š Fused results from {len([r for r in parallel_results.values() if r and not str(r).startswith('Error')])} successful tools\")\n",
        "\n",
        "    return {\n",
        "        \"final_context\": final_context\n",
        "    }"
      ],
      "metadata": {
        "id": "bvcRiB8jlDfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_generation_node(state: ParallelRAGState):\n",
        "    \"\"\"Generate final answer using fused context.\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    context = state[\"final_context\"]\n",
        "\n",
        "    # Create prompt for answer generation\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are an expert assistant that provides comprehensive, accurate answers using information from multiple sources.\n",
        "\n",
        "Context from parallel tool execution:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "1. Synthesize information from ALL available sources\n",
        "2. Provide a comprehensive answer that addresses the query completely\n",
        "3. Cite sources when possible (web, Wikipedia, arXiv, documents)\n",
        "4. If sources conflict, acknowledge the discrepancy\n",
        "5. Be specific and detailed in your response\"\"\"),\n",
        "        (\"human\", \"{query}\")\n",
        "    ])\n",
        "\n",
        "    # Generate response\n",
        "    response = llm.invoke(prompt.format_messages(context=context, query=query))\n",
        "\n",
        "    print(f\"âœ¨ Generated comprehensive answer with {len(context)} characters of context\")\n",
        "\n",
        "    return {\n",
        "        \"answer\": response.content,\n",
        "        \"messages\": [AIMessage(content=response.content)]\n",
        "    }"
      ],
      "metadata": {
        "id": "jOhQfGUrlGfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LangGraph workflow\n",
        "workflow = StateGraph(ParallelRAGState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"query_analysis\", query_analysis_node)\n",
        "workflow.add_node(\"parallel_execution\", parallel_tool_execution_node)\n",
        "workflow.add_node(\"result_fusion\", result_fusion_node)\n",
        "workflow.add_node(\"answer_generation\", answer_generation_node)\n",
        "\n",
        "# Define the flow\n",
        "workflow.add_edge(START, \"query_analysis\")\n",
        "workflow.add_edge(\"query_analysis\", \"parallel_execution\")\n",
        "workflow.add_edge(\"parallel_execution\", \"result_fusion\")\n",
        "workflow.add_edge(\"result_fusion\", \"answer_generation\")\n",
        "workflow.add_edge(\"answer_generation\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "G7NiyIbHlITO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_parallel_rag(query: str):\n",
        "    \"\"\"Run the parallel RAG system with a query.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸš€ PARALLEL TOOL-CALLING RAG SYSTEM\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize state\n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=query)],\n",
        "        \"query\": query,\n",
        "        \"tool_calls\": [],\n",
        "        \"tool_results\": {},\n",
        "        \"parallel_results\": {},\n",
        "        \"final_context\": \"\",\n",
        "        \"answer\": \"\"\n",
        "    }\n",
        "\n",
        "    # Run the workflow\n",
        "    result = app.invoke(initial_state)\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ“ FINAL ANSWER\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(result[\"answer\"])\n",
        "    print(f\"\\nâ±ï¸  Total execution time: {total_time:.2f}s\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Jg3S3WvTlKwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_queries = [\n",
        "    \"What are the latest developments in machine learning and RAG systems in 2025?\",\n",
        "    \"What is quantum computing and how does it work?\",\n",
        "    \"Recent research papers on large language models\",\n",
        "]\n",
        "\n",
        "# Load some sample documents first\n",
        "sample_urls = [\n",
        "    \"https://en.wikipedia.org/wiki/Retrieval-augmented_generation\",\n",
        "    \"https://en.wikipedia.org/wiki/Machine_learning\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ“¥ Loading sample documents...\")\n",
        "for url in sample_urls:\n",
        "    try:\n",
        "        result = document_loader_tool.invoke({\"url\": url})\n",
        "        print(f\"âœ“ {result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Error loading {url}: {e}\")\n",
        "\n",
        "# Run test queries\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n\\nğŸ” TEST QUERY {i}\")\n",
        "    result = run_parallel_rag(query)\n",
        "\n",
        "    if i < len(test_queries):\n",
        "        input(\"\\nPress Enter to continue to next query...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwnrmGvulOa_",
        "outputId": "c32e60b3-cf89-4617-fb2b-94b4975f7fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Loading sample documents...\n",
            "âœ“ Successfully loaded 1 documents from https://en.wikipedia.org/wiki/Retrieval-augmented_generation. Added to vector database.\n",
            "âœ“ Successfully loaded 1 documents from https://en.wikipedia.org/wiki/Machine_learning. Added to vector database.\n",
            "\n",
            "\n",
            "ğŸ” TEST QUERY 1\n",
            "\n",
            "============================================================\n",
            "ğŸš€ PARALLEL TOOL-CALLING RAG SYSTEM\n",
            "============================================================\n",
            "ğŸ” Query: What are the latest developments in machine learning and RAG systems in 2025?\n",
            "ğŸ› ï¸  Selected tools: vector_search_tool, web_search_tool, arxiv_search_tool\n",
            "âš¡ Executing 3 tools in parallel...\n",
            "âœ“ vector_search_tool completed in 0.06s\n",
            "âœ“ arxiv_search_tool completed in 1.04s\n",
            "âœ“ web_search_tool completed in 13.12s\n",
            "\n",
            "ğŸ¯ Parallel execution completed in 13.12s\n",
            "ğŸ“Š Fused results from 3 successful tools\n",
            "âœ¨ Generated comprehensive answer with 4628 characters of context\n",
            "\n",
            "============================================================\n",
            "ğŸ“ FINAL ANSWER\n",
            "============================================================\n",
            "**The landscape of machine learning (ML) and Retrievalâ€‘Augmented Generation (RAG) has moved forward dramatically in 2025.**  \n",
            "Below is a synthesis of the mostâ€‘relevant developments that have been reported across scholarly literature, Wikipedia reference articles, and industryâ€‘focused web sources up to Septemberâ€¯2025.\n",
            "\n",
            "---\n",
            "\n",
            "## 1. Machineâ€‘Learning Milestones in 2025  \n",
            "\n",
            "| Area | Whatâ€™s new in 2025 | Why it matters | Key references |\n",
            "|------|-------------------|----------------|----------------|\n",
            "| **Foundationâ€‘model scaling & efficiency** | â€¢ 2â€‘trillionâ€‘parameter multimodal models (e.g., *Geminiâ€‘2*, *LLaMAâ€‘3*) are now routinely fineâ€‘tuned with **parameterâ€‘efficient adapters** (LoRA, IAÂ³) that cut training cost by >â€¯80â€¯% while preserving performance. <br>â€¢ **Sparseâ€‘Mixtureâ€‘ofâ€‘Experts (MoE)** architectures have become productionâ€‘ready, allowing a single model to host dozens of expert pathways that are activated only for relevant inputs. | Enables â€œgiantâ€ models to be used on commodity GPUs and reduces carbon footprint. | General ML background â€“ Wikipedia â€œMachine learningâ€ entry describes the evolution of deep learning and the rise of largeâ€‘scale models. |\n",
            "| **Multimodal & embodied learning** | â€¢ Unified visionâ€‘languageâ€‘audioâ€‘code models (e.g., *OmniNetâ€‘5*) can ingest video, speech, and code in a single forward pass. <br>â€¢ **Embodied agents** trained with reinforcement learning from human feedback (RLHF) now exhibit *zeroâ€‘shot* planning across simulated robotics and virtual environments. | Bridges the gap between perception, language, and action, opening new useâ€‘cases in AR/VR, autonomous systems, and digital assistants. | Wikipedia â€œMachine learningâ€ notes the shift toward multimodal representation learning. |\n",
            "| **Selfâ€‘supervised & contrastive preâ€‘training** | â€¢ **Crossâ€‘lingual contrastive objectives** (e.g., *Xâ€‘CLOZE*) have dramatically improved lowâ€‘resource language performance, leveraging massive multilingual corpora. <br>â€¢ **Diffusionâ€‘based preâ€‘training** (textâ€‘toâ€‘text diffusion) is now a viable alternative to autoregressive preâ€‘training for generative tasks. | Improves data efficiency and widens coverage to underâ€‘represented languages and domains. | â€” |\n",
            "| **Robustness, alignment, and safety** | â€¢ **AIâ€‘aligned fineâ€‘tuning pipelines** that combine RLHF with *truthfulâ€‘QA* datasets have reduced hallucination rates in LLMs by ~30â€¯% (according to OpenAI internal benchmarks). <br>â€¢ **Formal verification tools** for neural nets (e.g., *Neurifyâ€‘2025*) are being integrated into modelâ€‘deployment pipelines to certify safety constraints. | Addresses the biggest commercial barrierâ€”trustworthy, reliable outputs. | â€” |\n",
            "| **New linguistic resources for multilingual ML** | â€¢ The **taggedPBC** (Parallel Bible Corpus) now includes **CoNLLâ€‘Uâ€‘formatted dependency annotations** for >â€¯1â€¯800 sentences across 1â€¯500+ languages (Ringâ€¯2025). <br>â€¢ Early experiments show that training multilingual parsers on this resource yields **>â€¯10â€¯% absolute gains** on typological wordâ€‘order prediction tasks (WALS, Grambank, Autotyp). | Provides a rare, highâ€‘quality syntactic signal for lowâ€‘resource languages, enabling better crossâ€‘lingual transfer and more accurate languageâ€‘specific generation. | Ringâ€¯2025 (arXiv) |\n",
            "| **Hardwareâ€‘software coâ€‘design** | â€¢ **Tensorâ€‘coreâ€‘optimized kernels** for MoE and diffusion models now deliver 2â€‘3Ã— speedâ€‘ups on NVIDIA H100 and AMD Instinct GPUs. <br>â€¢ **Edgeâ€‘AI ASICs** (e.g., *SambaNova Edge*) support onâ€‘device inference of 1â€‘Bâ€‘parameter models with subâ€‘100â€¯ms latency. | Makes it feasible to run sophisticated models at the edge, expanding realâ€‘time AI applications. | â€” |\n",
            "\n",
            "### Takeâ€‘away\n",
            "2025 is defined by **massive, multimodal foundation models that are becoming far more efficient and safer**, plus **new crossâ€‘linguistic resources (taggedPBC) that empower truly global AI**.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Retrievalâ€‘Augmented Generation (RAG) in 2025  \n",
            "\n",
            "RAG combines a **generative LLM** with a **retrieval component** (vector store, knowledge graph, or hybrid index) so that the model can ground its output in external data. The core idea is unchanged from the original RAG paper, but the ecosystem has matured dramatically.\n",
            "\n",
            "### 2.1 Architectural Innovations  \n",
            "\n",
            "| Innovation | Description | Impact |\n",
            "|------------|-------------|--------|\n",
            "| **Hybrid Retrieval (Denseâ€¯+â€¯Sparseâ€¯+â€¯Graph)** | Systems now fuse **dense vector similarity** (e.g., OpenAI embeddings), **sparse lexical BM25**, and **knowledgeâ€‘graph traversal** (GraphRAG) in a single retrieval pipeline. The hybrid score is learned endâ€‘toâ€‘end with the LLM. | Improves recall for both factual and relational queries; reduces â€œknowledge cutâ€‘offâ€ hallucinations. |\n",
            "| **GraphRAG / Knowledgeâ€‘Graphâ€‘Enhanced RAG** | Largeâ€‘scale **property graphs** (e.g., Neo4j, TigerGraph) are queried alongside vector stores. The LLM receives **structured subâ€‘graphs** (nodes + edges) as part of its prompt, enabling reasoning over entities and relations. | Enables chainâ€‘ofâ€‘thought style reasoning on factual data, useful for enterprise Q&A, compliance, and scientific literature synthesis. |\n",
            "| **LangChain Expression Language (LCEL)** | LangChain 2.0 introduced **LCEL**, a declarative DSL that lets developers compose retrieval, transformation, and generation steps in a single expression. LCEL can automatically parallelize retrieval across multiple backâ€‘ends. | Lowers engineering friction; speeds up prototyping of complex RAG pipelines. |\n",
            "| **Toolâ€‘use & Agentic RAG** | LLMs now **invoke external tools** (SQL, code execution, webâ€‘search APIs) as part of the generation loop, guided by a **planner** that decides when to retrieve vs. when to compute. | Turns RAG into a **general problemâ€‘solving engine**, not just a textâ€‘completion system. |\n",
            "| **Safetyâ€‘first Retrieval** | Retrieval layers are wrapped with **policy filters** (e.g., Pineconeâ€™s â€œSafeâ€‘Vectorâ€ layer) that block vectors linked to disallowed content, and **hallucination detectors** that flag generated statements lacking a supporting source. | Meets regulatory demands (e.g., EU AI Act) and corporate governance. |\n",
            "\n",
            "*Sources*: The **Squirro â€œState of RAG in 2025â€** article describes the shift toward GraphRAG and safetyâ€‘oriented retrieval pipelinesã€Webã€‘; the **Galileo AI â€œTop 12 RAG Building Toolsâ€** piece highlights LCEL and hybrid retrieval as the mostâ€‘adopted features in productionã€Webã€‘; the **Medium post on building RAG with Haystack and OpenAI** provides a concrete example of toolâ€‘use and evaluation metrics for RAG systemsã€Webã€‘.\n",
            "\n",
            "### 2.2 Tooling & Infrastructure Landscape  \n",
            "\n",
            "| Tool / Platform | Core Strength (2025) | Typical Useâ€‘Case |\n",
            "|-----------------|----------------------|------------------|\n",
            "| **Haystack 2.0** | Endâ€‘toâ€‘end pipelines with builtâ€‘in **document stores (FAISS, Milvus, Pinecone)**, **prompt templating**, and **evaluation harnesses** for RAG. Supports OpenAI, Anthropic, and Cohere LLMs. | Rapid prototyping of domainâ€‘specific Q&A bots. |\n",
            "| **Pinecone Vector DB** | **Realâ€‘time upserts**, **metadataâ€‘aware filtering**, and the new **Safeâ€‘Vector** layer that tags vectors with compliance tags. | Enterprise knowledge bases that must meet GDPR/AIâ€‘Act constraints. |\n",
            "| **LangChain 2.x + LCEL** | Declarative pipeline composition, **agentic tool calling**, and **autoâ€‘batching\n",
            "\n",
            "â±ï¸  Total execution time: 18.07s\n",
            "============================================================\n",
            "\n",
            "Press Enter to continue to next query...What is a RAG..?\n",
            "\n",
            "\n",
            "ğŸ” TEST QUERY 2\n",
            "\n",
            "============================================================\n",
            "ğŸš€ PARALLEL TOOL-CALLING RAG SYSTEM\n",
            "============================================================\n",
            "ğŸ” Query: What is quantum computing and how does it work?\n",
            "ğŸ› ï¸  Selected tools: vector_search_tool, wikipedia_search_tool\n",
            "âš¡ Executing 2 tools in parallel...\n",
            "âœ“ vector_search_tool completed in 0.14s\n",
            "âœ“ wikipedia_search_tool completed in 1.67s\n",
            "\n",
            "ğŸ¯ Parallel execution completed in 1.67s\n",
            "ğŸ“Š Fused results from 2 successful tools\n",
            "âœ¨ Generated comprehensive answer with 2324 characters of context\n",
            "\n",
            "============================================================\n",
            "ğŸ“ FINAL ANSWER\n",
            "============================================================\n",
            "**Quantum Computing â€“ A Concise Overview**\n",
            "\n",
            "| Aspect | Classical Computing | Quantum Computing |\n",
            "|--------|---------------------|-------------------|\n",
            "| **Basic unit of information** | Bit (0â€¯orâ€¯1) | **Qubit** â€“ can be 0, 1, or any quantum superpositionâ€¯Î±|0âŸ©â€¯+â€¯Î²|1âŸ© (|Î±|Â²â€¯+â€¯|Î²|Â²â€¯=â€¯1) |\n",
            "| **State space growth** | Linear: *n* bits â†’ 2â¿ possible *classical* states, but only one is realized at a time | Exponential: *n* qubits â†’ 2â¿â€‘dimensional Hilbert space that can be *simultaneously* explored via superposition |\n",
            "| **Key physical phenomena** | Electrical charge, voltage levels, transistor switching | **Superposition**, **Entanglement**, **Interference**, and **Quantum Coherence** |\n",
            "| **Typical operations** | Logic gates (AND, OR, NOT) that are deterministic | **Quantum gates** (Hadamard, CNOT, Phase, etc.) that are unitary, reversible, and manipulate amplitudes |\n",
            "| **Error source** | Thermal noise, manufacturing defects | **Decoherence** â€“ loss of quantum coherence to the environment (seeâ€¯[Quantum decoherence]Â¹) |\n",
            "| **Potential advantage** | Wellâ€‘established, universal for all tasks | Certain problems (factoring, unstructured search, quantum simulation) can be solved exponentially or quadratically faster (e.g., Shorâ€™s and Groverâ€™s algorithms) |\n",
            "\n",
            "---\n",
            "\n",
            "## 1. What Is Quantum Computing?\n",
            "\n",
            "Quantum computing is a model of information processing that **exploits the laws of quantum mechanics** to perform calculations. Instead of classical bits, it uses **quantum bits (qubits)** that can exist in a superposition of 0 and 1. When multiple qubits become **entangled**, the state of each qubit cannot be described independently; the whole register behaves as a single, highâ€‘dimensional quantum system. By carefully arranging quantum gates, a quantum computer can cause the amplitudes of different computational paths to **interfere** constructively for correct answers and destructively for wrong ones, thereby extracting the desired result with high probability.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Core Physical Principles\n",
            "\n",
            "| Principle | Description | Relevance to Computing |\n",
            "|-----------|-------------|------------------------|\n",
            "| **Superposition** | A qubit can be in a linear combination Î±|0âŸ©â€¯+â€¯Î²|1âŸ©. | Allows a register of *n* qubits to encode 2â¿ basis states simultaneously. |\n",
            "| **Entanglement** | Correlations that make the joint state of qubits inseparable. | Enables nonâ€‘local information sharing; essential for many quantum algorithms and errorâ€‘correcting codes. |\n",
            "| **Interference** | Quantum amplitudes add or cancel like waves. | Algorithmic step that amplifies the probability of correct outcomes. |\n",
            "| **Coherence** | Preservation of phase relationships among amplitudes. | Required for interference to be meaningful; loss of coherence = **decoherence** (seeâ€¯[Quantum decoherence]Â¹). |\n",
            "| **Measurement** | Collapses the superposition to a classical outcome (0 or 1) with probabilities |â€¯|Î±|Â² and |Î²|Â². | The only way to read out a result; must be timed after the algorithm has amplified the right answer. |\n",
            "\n",
            "---\n",
            "\n",
            "## 3. How a Quantum Computer Works â€“ From Bottomâ€‘Up\n",
            "\n",
            "### 3.1 Physical Qubits\n",
            "Various technologies realize qubits, each with its own tradeâ€‘offs:\n",
            "\n",
            "| Platform | Physical Realisation | Typical Coherence Times | Notable Milestones |\n",
            "|----------|----------------------|------------------------|--------------------|\n",
            "| Superconducting circuits | Josephson junctions (microwave resonators) | 10â€“100â€¯Âµs (now >â€¯200â€¯Âµs) | Google â€œSycamoreâ€ 53â€‘qubit processor (2020) |\n",
            "| Trapped ions | Hyperfine states of ions in electromagnetic traps | >â€¯seconds | Honeywell 64â€‘qubit trappedâ€‘ion system (2022) |\n",
            "| Photonic qubits | Polarisation or timeâ€‘bin of single photons | Limited by loss, but roomâ€‘temperature | Xanadu â€œBorealisâ€ 8â€‘mode Gaussian boson sampler |\n",
            "| Spin qubits (silicon, diamond NV) | Electron or nuclear spin | Up to milliseconds | Intel 2023 49â€‘qubit silicon spin chip |\n",
            "| Topological (Majorana) | Nonâ€‘abelian anyons (still experimental) | Theoretically protected | Ongoing research |\n",
            "\n",
            "All platforms must **initialize** qubits (prepare |0âŸ©), **apply** a sequence of quantum gates, **maintain coherence** throughout, and finally **measure**.\n",
            "\n",
            "### 3.2 Quantum Gates and Circuits\n",
            "Quantum gates are **unitary operators** acting on one or two qubits. Because they are reversible, any quantum algorithm can be expressed as a **quantum circuit**:\n",
            "\n",
            "* **Singleâ€‘qubit gates** â€“ e.g., Hadamard (H) creates equal superposition, Phase (S, T) adds relative phases.\n",
            "* **Twoâ€‘qubit entangling gates** â€“ e.g., CNOT, CZ, iSWAP. These are the â€œglueâ€ that spreads entanglement across the register.\n",
            "* **Universal gate set** â€“ A finite set (e.g., {H, T, CNOT}) can approximate any unitary to arbitrary precision (Solovayâ€‘Kitaev theorem).\n",
            "\n",
            "A circuit is executed by **pulsing** the hardware (microwave, laser, etc.) to enact the desired unitary transformations. The depth (number of sequential layers) determines how long the qubits must stay coherent.\n",
            "\n",
            "### 3.3 Algorithmic Flow (Simplified)\n",
            "\n",
            "1. **State preparation** â€“ Initialise all qubits to |0âŸ©.\n",
            "2. **Superposition** â€“ Apply H gates to create a uniform superposition over all basis states.\n",
            "3. **Problemâ€‘specific unitary** â€“ Encode the problem (e.g., modular exponentiation for Shorâ€™s algorithm) using a network of gates.\n",
            "4. **Interference step** â€“ Apply quantum Fourier transform or amplitude amplification (Grover) to concentrate probability on the correct answer.\n",
            "5. **Measurement** â€“ Collapse the register; repeat the whole circuit many times to obtain a statistical distribution from which the answer is inferred.\n",
            "\n",
            "### 3.4 Error Sources & Quantum Error Correction\n",
            "The biggest practical obstacle is **decoherence** â€“ uncontrolled interaction with the environment that randomises phases and destroys superpositionâ€¯[1]. Errors manifest as:\n",
            "\n",
            "* **Bitâ€‘flip (X)** â€“ |0âŸ© â†” |1âŸ©.\n",
            "* **Phaseâ€‘flip (Z)** â€“ |+âŸ© â†” |âˆ’âŸ©.\n",
            "* **Combined (Y)**.\n",
            "\n",
            "Quantum errorâ€‘correcting codes (e.g., **surface code**, **Steane code**) encode a logical qubit into many physical qubits, allowing detection and correction of errors without measuring the logical state. Faultâ€‘tolerant thresholds (â‰ˆâ€¯1â€¯% error per gate for the surface code) guide hardware development.\n",
            "\n",
            "---\n",
            "\n",
            "## 4. Representative Quantum Algorithms\n",
            "\n",
            "| Algorithm | Problem | Speedâ€‘up vs. Classical | Core Quantum Idea |\n",
            "|-----------|---------|------------------------|-------------------|\n",
            "| **Shorâ€™s algorithm** (1994) | Integer factorisation, discrete logarithms | Exponential (polyâ€‘time vs. subâ€‘exponential classical) | Quantum Fourier transform on periodicity of modular exponentiation. |\n",
            "| **Groverâ€™s search** (1996) | Unstructured search in N items | Quadratic (O(âˆšN) vs. O(N)) | Amplitude amplification via repeated oracle + diffusion operator. |\n",
            "| **Quantum Phase Estimation** | Eigenvalue estimation, used as subâ€‘routine | Enables many other algorithms (e.g., Hamiltonian simulation). |\n",
            "| **Variational Quantum Eigensolver (VQE)** | Approximate groundâ€‘state energies of molecules | Polynomial scaling for certain chemistry problems; hybrid quantumâ€‘classical optimisation. |\n",
            "| **Quantum Approximate Optimization Algorithm (QAOA)** | Approximate combinatorial optimisation | Promising for NPâ€‘hard problems; performance still under study. |\n",
            "\n",
            "These algorithms illustrate how **interference** and **entanglement** can be harnessed to solve specific tasks more efficiently than any known classical method.\n",
            "\n",
            "---\n",
            "\n",
            "## 5. Historical Context (Timeline Highlights)\n",
            "\n",
            "* **1980s** â€“ Conceptual foundations (Feynmanâ€™s â€œquantum simulatorâ€, Benioffâ€™s quantum Turing machine).  \n",
            "* **1994** â€“ Peter Shor publishes his factoring algorithm, sparking intense interest.  \n",
            "* **1996** â€“ Lov Grover introduces quantum search.  \n",
            "* **2001** â€“ First experimental demonstration of a 2â€‘qubit quantum gate (NIST).  \n",
            "* **2011â€‘2014** â€“ First smallâ€‘scale quantum processors (IBM, Dâ€‘Waveâ€™s quantum annealer).  \n",
            "* **2019** â€“ Google claims â€œquant\n",
            "\n",
            "â±ï¸  Total execution time: 6.20s\n",
            "============================================================\n",
            "\n",
            "Press Enter to continue to next query...quit\n",
            "\n",
            "\n",
            "ğŸ” TEST QUERY 3\n",
            "\n",
            "============================================================\n",
            "ğŸš€ PARALLEL TOOL-CALLING RAG SYSTEM\n",
            "============================================================\n",
            "ğŸ” Query: Recent research papers on large language models\n",
            "ğŸ› ï¸  Selected tools: vector_search_tool, web_search_tool, arxiv_search_tool\n",
            "âš¡ Executing 3 tools in parallel...\n",
            "âœ“ vector_search_tool completed in 0.02s\n",
            "âœ“ arxiv_search_tool completed in 0.61s\n",
            "âœ“ web_search_tool completed in 10.84s\n",
            "\n",
            "ğŸ¯ Parallel execution completed in 10.84s\n",
            "ğŸ“Š Fused results from 3 successful tools\n",
            "âœ¨ Generated comprehensive answer with 4549 characters of context\n",
            "\n",
            "============================================================\n",
            "ğŸ“ FINAL ANSWER\n",
            "============================================================\n",
            "Below is a curated, upâ€‘toâ€‘date (2022â€‘2024) list of research papers that have shaped the **large language model (LLM)** landscape in the last few years.  The papers are grouped by theme, each entry includes the full citation, venue (or preâ€‘print server), a short â€œtakeâ€‘awayâ€ summary, and a link to the PDF or publisher page when available.  Wherever possible the sources you provided (Wikipedia, the arXiv survey, the Nature â€œIndustrial applications of LLMsâ€ article, the Twoâ€‘Sigma NeurIPSâ€‘2023 roundup, and the AAAIâ€‘25 tutorial list) are referenced.\n",
            "\n",
            "---\n",
            "\n",
            "## 1ï¸âƒ£ Foundational/Scaleâ€‘Up LLMs (2022â€‘2024)\n",
            "\n",
            "| Year | Paper (Link) | Authors / Org. | Venue | Core Contribution |\n",
            "|------|--------------|----------------|-------|-------------------|\n",
            "| **2022** | **â€œScaling Laws for Neural Language Modelsâ€** <br> https://arxiv.org/abs/2001.08361 | Kaplan *etâ€¯al.* (OpenAI) | *arXiv* | Empirical laws that predict how loss improves with model size, dataset size, and compute â€“ the â€œscaling lawâ€ foundation for GPTâ€‘3â€‘style models. |\n",
            "| **2022** | **â€œPaLM: Scaling Language Modeling with Pathwaysâ€** <br> https://arxiv.org/abs/2204.02311 | Chowdhery *etâ€¯al.* (Google) | *arXiv* | 540â€‘Bâ€‘parameter dense transformer that introduced â€œPathwaysâ€ for efficient parallelism; set new fewâ€‘shot performance benchmarks. |\n",
            "| **2022** | **â€œLLaMA: Open and Efficient Foundation Language Modelsâ€** <br> https://arxiv.org/abs/2302.13971 | Touvron *etâ€¯al.* (Meta) | *arXiv* | 7â€‘Bâ€‘toâ€‘65â€‘Bâ€‘parameter models released under a researchâ€‘only license; demonstrated that strong performance can be achieved with fewer parameters when trained on highâ€‘quality data. |\n",
            "| **2023** | **â€œGPTâ€‘4 Technical Reportâ€** <br> https://arxiv.org/abs/2303.08774 | OpenAI | *arXiv* | First public technical description of GPTâ€‘4 (multimodal, 1â€‘trillionâ€‘parameter scale, improved alignment). |\n",
            "| **2023** | **â€œGemini: A Family of Highly Capable Multimodal Modelsâ€** <br> https://arxiv.org/abs/2312.11805 | Google DeepMind | *arXiv* | Introduces Geminiâ€‘1 (textâ€‘only) and Geminiâ€‘1.5 (textâ€‘+â€‘vision) models, highlighting instructionâ€‘tuning, safetyâ€‘steering, and multimodal reasoning. |\n",
            "| **2023** | **â€œA Survey of GPTâ€‘3 Family Large Language Models Including ChatGPT and GPTâ€‘4â€** <br> https://arxiv.org/abs/2310.04004 | Katikapalli Subramanyam Kalyan | *arXiv* (Octâ€¯2023) | Comprehensive taxonomy of GPTâ€‘3â€‘family models, their training regimes, evaluation, and emerging applications. *(source from the arXiv search tool)* |\n",
            "| **2024** | **â€œLLaMAâ€¯2: Open Foundation Language Modelsâ€** <br> https://arxiv.org/abs/2307.09288 | Touvron *etâ€¯al.* (Meta) | *arXiv* | 7â€‘B, 13â€‘B, and 70â€‘B parameter models with instructionâ€‘tuned variants; openâ€‘source weights and RLHFâ€‘style safety finetuning. |\n",
            "| **2024** | **â€œMistralâ€‘7B: A 7â€‘B Parameter Model Trained on 1â€¯Trillion Tokensâ€** <br> https://arxiv.org/abs/2402.01815 | Mistral AI | *arXiv* | Demonstrates that a 7â€‘B model can rival 30â€‘Bâ€‘plus models when trained on a highâ€‘quality, curated token stream. |\n",
            "\n",
            "---\n",
            "\n",
            "## 2ï¸âƒ£ Retrievalâ€‘Augmented Generation (RAG) & Knowledgeâ€‘Grounded LLMs  \n",
            "\n",
            "*(The Wikipedia entry on Retrievalâ€‘augmented generation (RAG) gives a highâ€‘level definition; the papers below flesh out the stateâ€‘ofâ€‘theâ€‘art.)*\n",
            "\n",
            "| Year | Paper (Link) | Authors | Venue | Takeâ€‘away |\n",
            "|------|--------------|---------|-------|-----------|\n",
            "| **2022** | **â€œRetrievalâ€‘Augmented Generation for Knowledgeâ€‘Intensive NLP Tasksâ€** <br> https://arxiv.org/abs/2005.11401 | Lewis *etâ€¯al.* (Facebook AI) | *ACL 2020 (preâ€‘print 2022)* | Introduced the **RAG** architecture (retriever + generator) that dramatically improves openâ€‘domain QA and factâ€‘checking. |\n",
            "| **2023** | **â€œAtlas: A Large Language Model with Integrated Retrievalâ€** <br> https://arxiv.org/abs/2309.07597 | Izacard *etâ€¯al.* (Meta) | *arXiv* | 11â€‘Bâ€‘parameter model that jointly learns retrieval and generation; achieves stateâ€‘ofâ€‘theâ€‘art on openâ€‘domain QA while keeping inference cheap. |\n",
            "| **2023** | **â€œSelfâ€‘RAG: Selfâ€‘Supervised Retrievalâ€‘Augmented Generationâ€** <br> https://arxiv.org/abs/2305.14223 | Liu *etâ€¯al.* (Microsoft) | *NeurIPS 2023* | Uses the LLM itself to generate pseudoâ€‘queries for building a retrieval index, removing the need for external annotators. |\n",
            "| **2024** | **â€œHybrid Retrievalâ€‘Augmented Generation for Longâ€‘Form Generationâ€** <br> https://arxiv.org/abs/2403.05678 | Zhou *etâ€¯al.* (Stanford) | *ICLR 2024* | Combines dense vector retrieval with symbolic knowledge graphs to produce coherent, citationâ€‘rich longâ€‘form answers. |\n",
            "| **2024** | **â€œIndustrial Applications of Large Language Modelsâ€** (Scientific Reports) <br> https://www.nature.com/articles/s41598-025-98483-1 | Various (Nature) | *Scientific Reports* (2025) | Survey of >100 papers (2020â€‘2024) on RAGâ€‘based solutions in finance, healthcare, and manufacturing; highlights practical deployment challenges (source from web search). |\n",
            "\n",
            "---\n",
            "\n",
            "## 3ï¸âƒ£ Instructionâ€‘Tuning, RLHF, and Alignment  \n",
            "\n",
            "| Year | Paper (Link) | Authors | Venue | Core Idea |\n",
            "|------|--------------|---------|-------|-----------|\n",
            "| **2022** | **â€œFineâ€‘Tuning Language Models from Human Preferencesâ€** <br> https://arxiv.org/abs/2203.02155 | Ziegler *etâ€¯al.* (OpenAI) | *ICLR 2022* | Early RLHF pipeline that aligns GPTâ€‘3â€‘style models with human feedback. |\n",
            "| **2023** | **â€œInstructGPT: Improving Language Models by Learning from Human Feedbackâ€** <br> https://arxiv.org/abs/2203.02155 | Ouyang *etâ€¯al.* (OpenAI) | *arXiv* | Scales RLHF to 175â€¯Bâ€‘parameter models; introduces â€œpreferenceâ€‘basedâ€ loss and a â€œreward modelâ€. |\n",
            "| **2023** | **â€œChatGPT: Optimizing Language Models for Dialogueâ€** (OpenAI blog + technical report) | OpenAI | *arXiv* (2023â€‘12) | Describes the iterative instructionâ€‘tuning and RLHF loop that produced ChatGPT. |\n",
            "| **2024** | **â€œSFTâ€‘RLHF: A Unified Framework for Supervised Fineâ€‘Tuning and Reinforcement Learning from Human Feedbackâ€** <br> https://arxiv.org/abs/2401.01845 | Bai *etâ€¯al.* (DeepMind) | *NeurIPS 2024* | Shows that a single-stage SFTâ€‘RLHF pipeline can match twoâ€‘stage pipelines while reducing compute. |\n",
            "| **202\n",
            "\n",
            "â±ï¸  Total execution time: 15.42s\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_system_stats():\n",
        "    \"\"\"Get system performance statistics.\"\"\"\n",
        "    stats = {\n",
        "        \"vector_db_docs\": vectorstore._collection.count(),\n",
        "        \"available_tools\": [\"web_search\", \"wikipedia\", \"arxiv\", \"vector_search\", \"document_loader\"],\n",
        "        \"parallel_execution\": \"enabled\",\n",
        "        \"intelligent_routing\": \"enabled\"\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "get_system_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7r62CQ3lSNy",
        "outputId": "516bf614-b3a0-4f1b-a327-d7177dce7015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vector_db_docs': 4,\n",
              " 'available_tools': ['web_search',\n",
              "  'wikipedia',\n",
              "  'arxiv',\n",
              "  'vector_search',\n",
              "  'document_loader'],\n",
              " 'parallel_execution': 'enabled',\n",
              " 'intelligent_routing': 'enabled'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ScxW4LZvmI48"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}