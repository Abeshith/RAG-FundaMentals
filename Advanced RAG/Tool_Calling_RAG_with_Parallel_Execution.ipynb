{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mulTiViHeIWd"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-groq langchain-huggingface langchain-chroma langchain-community langchain_tavily\n",
        "!pip install -q chromadb sentence-transformers requests wikipedia-api python-dotenv wikipedia\n",
        "!pip install -qU beautifulsoup4 requests chromadb arxiv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "id": "cTUSZxMyiuhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SmJ9994GhwpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from typing import TypedDict, Annotated, List, Dict, Any\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time"
      ],
      "metadata": {
        "id": "bP4ouhj8iouo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langchain_core.tools import tool, StructuredTool\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
        "from langchain_tavily import TavilySearch"
      ],
      "metadata": {
        "id": "wOmt03RYipqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode"
      ],
      "metadata": {
        "id": "rDrW-cGCitdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "uh2U7OKifBgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=2048\n",
        ")"
      ],
      "metadata": {
        "id": "a7DHbU9rfmNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")"
      ],
      "metadata": {
        "id": "QV2xxhKdfu_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma(\n",
        "    collection_name=\"parallel_rag\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")"
      ],
      "metadata": {
        "id": "J3EYplQgkGrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def web_search_tool(query: str) -> str:\n",
        "    \"\"\"Search the web for current information using Tavily.\"\"\"\n",
        "    tavily_search = TavilySearch(\n",
        "        max_results=3,\n",
        "        topic=\"general\",\n",
        "        include_raw_content=True,\n",
        "        search_depth=\"advanced\"\n",
        "    )\n",
        "    results = tavily_search.invoke({\"query\": query})\n",
        "\n",
        "    formatted_results = []\n",
        "    for result in results.get('results', []):\n",
        "        formatted_results.append(f\"Title: {result['title']}\\nURL: {result['url']}\\nContent: {result['content'][:500]}...\")\n",
        "\n",
        "    return \"\\n\\n\".join(formatted_results)"
      ],
      "metadata": {
        "id": "y8MSAc3RkITv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def wikipedia_search_tool(query: str) -> str:\n",
        "    \"\"\"Search Wikipedia for encyclopedic information.\"\"\"\n",
        "    wikipedia = WikipediaQueryRun(\n",
        "        api_wrapper=WikipediaAPIWrapper(\n",
        "            top_k_results=2,\n",
        "            doc_content_chars_max=1000\n",
        "        )\n",
        "    )\n",
        "    return wikipedia.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "Q87C5F9NkbST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def arxiv_search_tool(query: str) -> str:\n",
        "    \"\"\"Search arXiv for academic papers and research.\"\"\"\n",
        "    arxiv = ArxivQueryRun(\n",
        "        api_wrapper=ArxivAPIWrapper(\n",
        "            top_k_results=2,\n",
        "            doc_content_chars_max=1000\n",
        "        )\n",
        "    )\n",
        "    return arxiv.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "do8yQDuVkd3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def vector_search_tool(query: str) -> str:\n",
        "    \"\"\"Search the vector database for relevant documents.\"\"\"\n",
        "    if vectorstore._collection.count() == 0:\n",
        "        return \"Vector database is empty. Please load documents first.\"\n",
        "\n",
        "    docs = vectorstore.similarity_search(query, k=3)\n",
        "    results = []\n",
        "    for doc in docs:\n",
        "        results.append(f\"Content: {doc.page_content[:500]}...\")\n",
        "    return \"\\n\\n\".join(results)"
      ],
      "metadata": {
        "id": "z5kyQp4jkyXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def document_loader_tool(url: str) -> str:\n",
        "    \"\"\"Load and process documents from web URLs.\"\"\"\n",
        "    try:\n",
        "        loader = WebBaseLoader([url])\n",
        "        docs = loader.load()\n",
        "\n",
        "        # Add to vector store\n",
        "        vectorstore.add_documents(docs)\n",
        "\n",
        "        return f\"Successfully loaded {len(docs)} documents from {url}. Added to vector database.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error loading document from {url}: {str(e)}\""
      ],
      "metadata": {
        "id": "r0x1CDo9k0qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParallelRAGState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    query: str\n",
        "    tool_calls: List[Dict[str, Any]]\n",
        "    tool_results: Dict[str, Any]\n",
        "    parallel_results: Dict[str, Any]\n",
        "    final_context: str\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "nS0YgjN2k2Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_and_select_tools(query: str) -> List[str]:\n",
        "    \"\"\"Intelligently route query to appropriate tools based on content.\"\"\"\n",
        "    query_lower = query.lower()\n",
        "    selected_tools = []\n",
        "\n",
        "    # Always include vector search if we have documents\n",
        "    if vectorstore._collection.count() > 0:\n",
        "        selected_tools.append(\"vector_search_tool\")\n",
        "\n",
        "    # Add web search for current information\n",
        "    if any(keyword in query_lower for keyword in [\"latest\", \"recent\", \"current\", \"news\", \"2024\", \"2025\"]):\n",
        "        selected_tools.append(\"web_search_tool\")\n",
        "\n",
        "    # Add Wikipedia for general knowledge\n",
        "    if any(keyword in query_lower for keyword in [\"what is\", \"who is\", \"definition\", \"history\", \"concept\"]):\n",
        "        selected_tools.append(\"wikipedia_search_tool\")\n",
        "\n",
        "    # Add arXiv for research topics\n",
        "    if any(keyword in query_lower for keyword in [\"research\", \"study\", \"algorithm\", \"machine learning\", \"AI\", \"paper\"]):\n",
        "        selected_tools.append(\"arxiv_search_tool\")\n",
        "\n",
        "    # Ensure at least web search and wikipedia\n",
        "    if not selected_tools:\n",
        "        selected_tools = [\"web_search_tool\", \"wikipedia_search_tool\"]\n",
        "\n",
        "    return selected_tools"
      ],
      "metadata": {
        "id": "i5BpwxbUk64r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_tools_in_parallel(tools_to_execute: List[str], query: str) -> Dict[str, Any]:\n",
        "    \"\"\"Execute multiple tools in parallel using ThreadPoolExecutor.\"\"\"\n",
        "    tool_map = {\n",
        "        \"web_search_tool\": web_search_tool,\n",
        "        \"wikipedia_search_tool\": wikipedia_search_tool,\n",
        "        \"arxiv_search_tool\": arxiv_search_tool,\n",
        "        \"vector_search_tool\": vector_search_tool\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    start_time = time.time()\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=len(tools_to_execute)) as executor:\n",
        "        # Submit all tool executions\n",
        "        future_to_tool = {\n",
        "            executor.submit(tool_map[tool_name].invoke, {\"query\": query}): tool_name\n",
        "            for tool_name in tools_to_execute if tool_name in tool_map\n",
        "        }\n",
        "\n",
        "        # Collect results as they complete\n",
        "        for future in as_completed(future_to_tool):\n",
        "            tool_name = future_to_tool[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                results[tool_name] = result\n",
        "                print(f\"✓ {tool_name} completed in {time.time() - start_time:.2f}s\")\n",
        "            except Exception as e:\n",
        "                results[tool_name] = f\"Error: {str(e)}\"\n",
        "                print(f\"✗ {tool_name} failed: {str(e)}\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\n🎯 Parallel execution completed in {total_time:.2f}s\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "G1hLpTZlk8vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_analysis_node(state: ParallelRAGState):\n",
        "    \"\"\"Analyze the query and determine which tools to use.\"\"\"\n",
        "    query = state[\"messages\"][-1].content if state[\"messages\"] else state.get(\"query\", \"\")\n",
        "\n",
        "    # Route to appropriate tools\n",
        "    selected_tools = route_and_select_tools(query)\n",
        "\n",
        "    print(f\"🔍 Query: {query}\")\n",
        "    print(f\"🛠️  Selected tools: {', '.join(selected_tools)}\")\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"tool_calls\": [{\"tool\": tool, \"query\": query} for tool in selected_tools]\n",
        "    }"
      ],
      "metadata": {
        "id": "q9Ct5x1gk_Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_tool_execution_node(state: ParallelRAGState):\n",
        "    \"\"\"Execute tools in parallel and collect results.\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    tool_calls = state[\"tool_calls\"]\n",
        "\n",
        "    # Extract tool names\n",
        "    tools_to_execute = [call[\"tool\"] for call in tool_calls]\n",
        "\n",
        "    print(f\"⚡ Executing {len(tools_to_execute)} tools in parallel...\")\n",
        "\n",
        "    # Execute tools in parallel\n",
        "    parallel_results = execute_tools_in_parallel(tools_to_execute, query)\n",
        "\n",
        "    return {\n",
        "        \"parallel_results\": parallel_results,\n",
        "        \"tool_results\": parallel_results\n",
        "    }"
      ],
      "metadata": {
        "id": "eS32JX-slAqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def result_fusion_node(state: ParallelRAGState):\n",
        "    \"\"\"Fuse and rank results from parallel tool execution.\"\"\"\n",
        "    parallel_results = state[\"parallel_results\"]\n",
        "    query = state[\"query\"]\n",
        "\n",
        "    # Combine and weight results\n",
        "    combined_context = []\n",
        "\n",
        "    for tool_name, result in parallel_results.items():\n",
        "        if result and not result.startswith(\"Error\"):\n",
        "            # Add source attribution\n",
        "            combined_context.append(f\"=== {tool_name.upper().replace('_', ' ')} ===\\n{result}\\n\")\n",
        "\n",
        "    # Create final context\n",
        "    final_context = \"\\n\".join(combined_context)\n",
        "\n",
        "    print(f\"📊 Fused results from {len([r for r in parallel_results.values() if r and not str(r).startswith('Error')])} successful tools\")\n",
        "\n",
        "    return {\n",
        "        \"final_context\": final_context\n",
        "    }"
      ],
      "metadata": {
        "id": "bvcRiB8jlDfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_generation_node(state: ParallelRAGState):\n",
        "    \"\"\"Generate final answer using fused context.\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    context = state[\"final_context\"]\n",
        "\n",
        "    # Create prompt for answer generation\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are an expert assistant that provides comprehensive, accurate answers using information from multiple sources.\n",
        "\n",
        "Context from parallel tool execution:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "1. Synthesize information from ALL available sources\n",
        "2. Provide a comprehensive answer that addresses the query completely\n",
        "3. Cite sources when possible (web, Wikipedia, arXiv, documents)\n",
        "4. If sources conflict, acknowledge the discrepancy\n",
        "5. Be specific and detailed in your response\"\"\"),\n",
        "        (\"human\", \"{query}\")\n",
        "    ])\n",
        "\n",
        "    # Generate response\n",
        "    response = llm.invoke(prompt.format_messages(context=context, query=query))\n",
        "\n",
        "    print(f\"✨ Generated comprehensive answer with {len(context)} characters of context\")\n",
        "\n",
        "    return {\n",
        "        \"answer\": response.content,\n",
        "        \"messages\": [AIMessage(content=response.content)]\n",
        "    }"
      ],
      "metadata": {
        "id": "jOhQfGUrlGfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LangGraph workflow\n",
        "workflow = StateGraph(ParallelRAGState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"query_analysis\", query_analysis_node)\n",
        "workflow.add_node(\"parallel_execution\", parallel_tool_execution_node)\n",
        "workflow.add_node(\"result_fusion\", result_fusion_node)\n",
        "workflow.add_node(\"answer_generation\", answer_generation_node)\n",
        "\n",
        "# Define the flow\n",
        "workflow.add_edge(START, \"query_analysis\")\n",
        "workflow.add_edge(\"query_analysis\", \"parallel_execution\")\n",
        "workflow.add_edge(\"parallel_execution\", \"result_fusion\")\n",
        "workflow.add_edge(\"result_fusion\", \"answer_generation\")\n",
        "workflow.add_edge(\"answer_generation\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "G7NiyIbHlITO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_parallel_rag(query: str):\n",
        "    \"\"\"Run the parallel RAG system with a query.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🚀 PARALLEL TOOL-CALLING RAG SYSTEM\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize state\n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=query)],\n",
        "        \"query\": query,\n",
        "        \"tool_calls\": [],\n",
        "        \"tool_results\": {},\n",
        "        \"parallel_results\": {},\n",
        "        \"final_context\": \"\",\n",
        "        \"answer\": \"\"\n",
        "    }\n",
        "\n",
        "    # Run the workflow\n",
        "    result = app.invoke(initial_state)\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"📝 FINAL ANSWER\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(result[\"answer\"])\n",
        "    print(f\"\\n⏱️  Total execution time: {total_time:.2f}s\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Jg3S3WvTlKwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_queries = [\n",
        "    \"What are the latest developments in machine learning and RAG systems in 2025?\",\n",
        "    \"What is quantum computing and how does it work?\",\n",
        "    \"Recent research papers on large language models\",\n",
        "]\n",
        "\n",
        "# Load some sample documents first\n",
        "sample_urls = [\n",
        "    \"https://en.wikipedia.org/wiki/Retrieval-augmented_generation\",\n",
        "    \"https://en.wikipedia.org/wiki/Machine_learning\"\n",
        "]\n",
        "\n",
        "print(\"📥 Loading sample documents...\")\n",
        "for url in sample_urls:\n",
        "    try:\n",
        "        result = document_loader_tool.invoke({\"url\": url})\n",
        "        print(f\"✓ {result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading {url}: {e}\")\n",
        "\n",
        "# Run test queries\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n\\n🔍 TEST QUERY {i}\")\n",
        "    result = run_parallel_rag(query)\n",
        "\n",
        "    if i < len(test_queries):\n",
        "        input(\"\\nPress Enter to continue to next query...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwnrmGvulOa_",
        "outputId": "c32e60b3-cf89-4617-fb2b-94b4975f7fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Loading sample documents...\n",
            "✓ Successfully loaded 1 documents from https://en.wikipedia.org/wiki/Retrieval-augmented_generation. Added to vector database.\n",
            "✓ Successfully loaded 1 documents from https://en.wikipedia.org/wiki/Machine_learning. Added to vector database.\n",
            "\n",
            "\n",
            "🔍 TEST QUERY 1\n",
            "\n",
            "============================================================\n",
            "🚀 PARALLEL TOOL-CALLING RAG SYSTEM\n",
            "============================================================\n",
            "🔍 Query: What are the latest developments in machine learning and RAG systems in 2025?\n",
            "🛠️  Selected tools: vector_search_tool, web_search_tool, arxiv_search_tool\n",
            "⚡ Executing 3 tools in parallel...\n",
            "✓ vector_search_tool completed in 0.06s\n",
            "✓ arxiv_search_tool completed in 1.04s\n",
            "✓ web_search_tool completed in 13.12s\n",
            "\n",
            "🎯 Parallel execution completed in 13.12s\n",
            "📊 Fused results from 3 successful tools\n",
            "✨ Generated comprehensive answer with 4628 characters of context\n",
            "\n",
            "============================================================\n",
            "📝 FINAL ANSWER\n",
            "============================================================\n",
            "**The landscape of machine learning (ML) and Retrieval‑Augmented Generation (RAG) has moved forward dramatically in 2025.**  \n",
            "Below is a synthesis of the most‑relevant developments that have been reported across scholarly literature, Wikipedia reference articles, and industry‑focused web sources up to September 2025.\n",
            "\n",
            "---\n",
            "\n",
            "## 1. Machine‑Learning Milestones in 2025  \n",
            "\n",
            "| Area | What’s new in 2025 | Why it matters | Key references |\n",
            "|------|-------------------|----------------|----------------|\n",
            "| **Foundation‑model scaling & efficiency** | • 2‑trillion‑parameter multimodal models (e.g., *Gemini‑2*, *LLaMA‑3*) are now routinely fine‑tuned with **parameter‑efficient adapters** (LoRA, IA³) that cut training cost by > 80 % while preserving performance. <br>• **Sparse‑Mixture‑of‑Experts (MoE)** architectures have become production‑ready, allowing a single model to host dozens of expert pathways that are activated only for relevant inputs. | Enables “giant” models to be used on commodity GPUs and reduces carbon footprint. | General ML background – Wikipedia “Machine learning” entry describes the evolution of deep learning and the rise of large‑scale models. |\n",
            "| **Multimodal & embodied learning** | • Unified vision‑language‑audio‑code models (e.g., *OmniNet‑5*) can ingest video, speech, and code in a single forward pass. <br>• **Embodied agents** trained with reinforcement learning from human feedback (RLHF) now exhibit *zero‑shot* planning across simulated robotics and virtual environments. | Bridges the gap between perception, language, and action, opening new use‑cases in AR/VR, autonomous systems, and digital assistants. | Wikipedia “Machine learning” notes the shift toward multimodal representation learning. |\n",
            "| **Self‑supervised & contrastive pre‑training** | • **Cross‑lingual contrastive objectives** (e.g., *X‑CLOZE*) have dramatically improved low‑resource language performance, leveraging massive multilingual corpora. <br>• **Diffusion‑based pre‑training** (text‑to‑text diffusion) is now a viable alternative to autoregressive pre‑training for generative tasks. | Improves data efficiency and widens coverage to under‑represented languages and domains. | — |\n",
            "| **Robustness, alignment, and safety** | • **AI‑aligned fine‑tuning pipelines** that combine RLHF with *truthful‑QA* datasets have reduced hallucination rates in LLMs by ~30 % (according to OpenAI internal benchmarks). <br>• **Formal verification tools** for neural nets (e.g., *Neurify‑2025*) are being integrated into model‑deployment pipelines to certify safety constraints. | Addresses the biggest commercial barrier—trustworthy, reliable outputs. | — |\n",
            "| **New linguistic resources for multilingual ML** | • The **taggedPBC** (Parallel Bible Corpus) now includes **CoNLL‑U‑formatted dependency annotations** for > 1 800 sentences across 1 500+ languages (Ring 2025). <br>• Early experiments show that training multilingual parsers on this resource yields **> 10 % absolute gains** on typological word‑order prediction tasks (WALS, Grambank, Autotyp). | Provides a rare, high‑quality syntactic signal for low‑resource languages, enabling better cross‑lingual transfer and more accurate language‑specific generation. | Ring 2025 (arXiv) |\n",
            "| **Hardware‑software co‑design** | • **Tensor‑core‑optimized kernels** for MoE and diffusion models now deliver 2‑3× speed‑ups on NVIDIA H100 and AMD Instinct GPUs. <br>• **Edge‑AI ASICs** (e.g., *SambaNova Edge*) support on‑device inference of 1‑B‑parameter models with sub‑100 ms latency. | Makes it feasible to run sophisticated models at the edge, expanding real‑time AI applications. | — |\n",
            "\n",
            "### Take‑away\n",
            "2025 is defined by **massive, multimodal foundation models that are becoming far more efficient and safer**, plus **new cross‑linguistic resources (taggedPBC) that empower truly global AI**.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Retrieval‑Augmented Generation (RAG) in 2025  \n",
            "\n",
            "RAG combines a **generative LLM** with a **retrieval component** (vector store, knowledge graph, or hybrid index) so that the model can ground its output in external data. The core idea is unchanged from the original RAG paper, but the ecosystem has matured dramatically.\n",
            "\n",
            "### 2.1 Architectural Innovations  \n",
            "\n",
            "| Innovation | Description | Impact |\n",
            "|------------|-------------|--------|\n",
            "| **Hybrid Retrieval (Dense + Sparse + Graph)** | Systems now fuse **dense vector similarity** (e.g., OpenAI embeddings), **sparse lexical BM25**, and **knowledge‑graph traversal** (GraphRAG) in a single retrieval pipeline. The hybrid score is learned end‑to‑end with the LLM. | Improves recall for both factual and relational queries; reduces “knowledge cut‑off” hallucinations. |\n",
            "| **GraphRAG / Knowledge‑Graph‑Enhanced RAG** | Large‑scale **property graphs** (e.g., Neo4j, TigerGraph) are queried alongside vector stores. The LLM receives **structured sub‑graphs** (nodes + edges) as part of its prompt, enabling reasoning over entities and relations. | Enables chain‑of‑thought style reasoning on factual data, useful for enterprise Q&A, compliance, and scientific literature synthesis. |\n",
            "| **LangChain Expression Language (LCEL)** | LangChain 2.0 introduced **LCEL**, a declarative DSL that lets developers compose retrieval, transformation, and generation steps in a single expression. LCEL can automatically parallelize retrieval across multiple back‑ends. | Lowers engineering friction; speeds up prototyping of complex RAG pipelines. |\n",
            "| **Tool‑use & Agentic RAG** | LLMs now **invoke external tools** (SQL, code execution, web‑search APIs) as part of the generation loop, guided by a **planner** that decides when to retrieve vs. when to compute. | Turns RAG into a **general problem‑solving engine**, not just a text‑completion system. |\n",
            "| **Safety‑first Retrieval** | Retrieval layers are wrapped with **policy filters** (e.g., Pinecone’s “Safe‑Vector” layer) that block vectors linked to disallowed content, and **hallucination detectors** that flag generated statements lacking a supporting source. | Meets regulatory demands (e.g., EU AI Act) and corporate governance. |\n",
            "\n",
            "*Sources*: The **Squirro “State of RAG in 2025”** article describes the shift toward GraphRAG and safety‑oriented retrieval pipelines【Web】; the **Galileo AI “Top 12 RAG Building Tools”** piece highlights LCEL and hybrid retrieval as the most‑adopted features in production【Web】; the **Medium post on building RAG with Haystack and OpenAI** provides a concrete example of tool‑use and evaluation metrics for RAG systems【Web】.\n",
            "\n",
            "### 2.2 Tooling & Infrastructure Landscape  \n",
            "\n",
            "| Tool / Platform | Core Strength (2025) | Typical Use‑Case |\n",
            "|-----------------|----------------------|------------------|\n",
            "| **Haystack 2.0** | End‑to‑end pipelines with built‑in **document stores (FAISS, Milvus, Pinecone)**, **prompt templating**, and **evaluation harnesses** for RAG. Supports OpenAI, Anthropic, and Cohere LLMs. | Rapid prototyping of domain‑specific Q&A bots. |\n",
            "| **Pinecone Vector DB** | **Real‑time upserts**, **metadata‑aware filtering**, and the new **Safe‑Vector** layer that tags vectors with compliance tags. | Enterprise knowledge bases that must meet GDPR/AI‑Act constraints. |\n",
            "| **LangChain 2.x + LCEL** | Declarative pipeline composition, **agentic tool calling**, and **auto‑batching\n",
            "\n",
            "⏱️  Total execution time: 18.07s\n",
            "============================================================\n",
            "\n",
            "Press Enter to continue to next query...What is a RAG..?\n",
            "\n",
            "\n",
            "🔍 TEST QUERY 2\n",
            "\n",
            "============================================================\n",
            "🚀 PARALLEL TOOL-CALLING RAG SYSTEM\n",
            "============================================================\n",
            "🔍 Query: What is quantum computing and how does it work?\n",
            "🛠️  Selected tools: vector_search_tool, wikipedia_search_tool\n",
            "⚡ Executing 2 tools in parallel...\n",
            "✓ vector_search_tool completed in 0.14s\n",
            "✓ wikipedia_search_tool completed in 1.67s\n",
            "\n",
            "🎯 Parallel execution completed in 1.67s\n",
            "📊 Fused results from 2 successful tools\n",
            "✨ Generated comprehensive answer with 2324 characters of context\n",
            "\n",
            "============================================================\n",
            "📝 FINAL ANSWER\n",
            "============================================================\n",
            "**Quantum Computing – A Concise Overview**\n",
            "\n",
            "| Aspect | Classical Computing | Quantum Computing |\n",
            "|--------|---------------------|-------------------|\n",
            "| **Basic unit of information** | Bit (0 or 1) | **Qubit** – can be 0, 1, or any quantum superposition α|0⟩ + β|1⟩ (|α|² + |β|² = 1) |\n",
            "| **State space growth** | Linear: *n* bits → 2ⁿ possible *classical* states, but only one is realized at a time | Exponential: *n* qubits → 2ⁿ‑dimensional Hilbert space that can be *simultaneously* explored via superposition |\n",
            "| **Key physical phenomena** | Electrical charge, voltage levels, transistor switching | **Superposition**, **Entanglement**, **Interference**, and **Quantum Coherence** |\n",
            "| **Typical operations** | Logic gates (AND, OR, NOT) that are deterministic | **Quantum gates** (Hadamard, CNOT, Phase, etc.) that are unitary, reversible, and manipulate amplitudes |\n",
            "| **Error source** | Thermal noise, manufacturing defects | **Decoherence** – loss of quantum coherence to the environment (see [Quantum decoherence]¹) |\n",
            "| **Potential advantage** | Well‑established, universal for all tasks | Certain problems (factoring, unstructured search, quantum simulation) can be solved exponentially or quadratically faster (e.g., Shor’s and Grover’s algorithms) |\n",
            "\n",
            "---\n",
            "\n",
            "## 1. What Is Quantum Computing?\n",
            "\n",
            "Quantum computing is a model of information processing that **exploits the laws of quantum mechanics** to perform calculations. Instead of classical bits, it uses **quantum bits (qubits)** that can exist in a superposition of 0 and 1. When multiple qubits become **entangled**, the state of each qubit cannot be described independently; the whole register behaves as a single, high‑dimensional quantum system. By carefully arranging quantum gates, a quantum computer can cause the amplitudes of different computational paths to **interfere** constructively for correct answers and destructively for wrong ones, thereby extracting the desired result with high probability.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Core Physical Principles\n",
            "\n",
            "| Principle | Description | Relevance to Computing |\n",
            "|-----------|-------------|------------------------|\n",
            "| **Superposition** | A qubit can be in a linear combination α|0⟩ + β|1⟩. | Allows a register of *n* qubits to encode 2ⁿ basis states simultaneously. |\n",
            "| **Entanglement** | Correlations that make the joint state of qubits inseparable. | Enables non‑local information sharing; essential for many quantum algorithms and error‑correcting codes. |\n",
            "| **Interference** | Quantum amplitudes add or cancel like waves. | Algorithmic step that amplifies the probability of correct outcomes. |\n",
            "| **Coherence** | Preservation of phase relationships among amplitudes. | Required for interference to be meaningful; loss of coherence = **decoherence** (see [Quantum decoherence]¹). |\n",
            "| **Measurement** | Collapses the superposition to a classical outcome (0 or 1) with probabilities | |α|² and |β|². | The only way to read out a result; must be timed after the algorithm has amplified the right answer. |\n",
            "\n",
            "---\n",
            "\n",
            "## 3. How a Quantum Computer Works – From Bottom‑Up\n",
            "\n",
            "### 3.1 Physical Qubits\n",
            "Various technologies realize qubits, each with its own trade‑offs:\n",
            "\n",
            "| Platform | Physical Realisation | Typical Coherence Times | Notable Milestones |\n",
            "|----------|----------------------|------------------------|--------------------|\n",
            "| Superconducting circuits | Josephson junctions (microwave resonators) | 10–100 µs (now > 200 µs) | Google “Sycamore” 53‑qubit processor (2020) |\n",
            "| Trapped ions | Hyperfine states of ions in electromagnetic traps | > seconds | Honeywell 64‑qubit trapped‑ion system (2022) |\n",
            "| Photonic qubits | Polarisation or time‑bin of single photons | Limited by loss, but room‑temperature | Xanadu “Borealis” 8‑mode Gaussian boson sampler |\n",
            "| Spin qubits (silicon, diamond NV) | Electron or nuclear spin | Up to milliseconds | Intel 2023 49‑qubit silicon spin chip |\n",
            "| Topological (Majorana) | Non‑abelian anyons (still experimental) | Theoretically protected | Ongoing research |\n",
            "\n",
            "All platforms must **initialize** qubits (prepare |0⟩), **apply** a sequence of quantum gates, **maintain coherence** throughout, and finally **measure**.\n",
            "\n",
            "### 3.2 Quantum Gates and Circuits\n",
            "Quantum gates are **unitary operators** acting on one or two qubits. Because they are reversible, any quantum algorithm can be expressed as a **quantum circuit**:\n",
            "\n",
            "* **Single‑qubit gates** – e.g., Hadamard (H) creates equal superposition, Phase (S, T) adds relative phases.\n",
            "* **Two‑qubit entangling gates** – e.g., CNOT, CZ, iSWAP. These are the “glue” that spreads entanglement across the register.\n",
            "* **Universal gate set** – A finite set (e.g., {H, T, CNOT}) can approximate any unitary to arbitrary precision (Solovay‑Kitaev theorem).\n",
            "\n",
            "A circuit is executed by **pulsing** the hardware (microwave, laser, etc.) to enact the desired unitary transformations. The depth (number of sequential layers) determines how long the qubits must stay coherent.\n",
            "\n",
            "### 3.3 Algorithmic Flow (Simplified)\n",
            "\n",
            "1. **State preparation** – Initialise all qubits to |0⟩.\n",
            "2. **Superposition** – Apply H gates to create a uniform superposition over all basis states.\n",
            "3. **Problem‑specific unitary** – Encode the problem (e.g., modular exponentiation for Shor’s algorithm) using a network of gates.\n",
            "4. **Interference step** – Apply quantum Fourier transform or amplitude amplification (Grover) to concentrate probability on the correct answer.\n",
            "5. **Measurement** – Collapse the register; repeat the whole circuit many times to obtain a statistical distribution from which the answer is inferred.\n",
            "\n",
            "### 3.4 Error Sources & Quantum Error Correction\n",
            "The biggest practical obstacle is **decoherence** – uncontrolled interaction with the environment that randomises phases and destroys superposition [1]. Errors manifest as:\n",
            "\n",
            "* **Bit‑flip (X)** – |0⟩ ↔ |1⟩.\n",
            "* **Phase‑flip (Z)** – |+⟩ ↔ |−⟩.\n",
            "* **Combined (Y)**.\n",
            "\n",
            "Quantum error‑correcting codes (e.g., **surface code**, **Steane code**) encode a logical qubit into many physical qubits, allowing detection and correction of errors without measuring the logical state. Fault‑tolerant thresholds (≈ 1 % error per gate for the surface code) guide hardware development.\n",
            "\n",
            "---\n",
            "\n",
            "## 4. Representative Quantum Algorithms\n",
            "\n",
            "| Algorithm | Problem | Speed‑up vs. Classical | Core Quantum Idea |\n",
            "|-----------|---------|------------------------|-------------------|\n",
            "| **Shor’s algorithm** (1994) | Integer factorisation, discrete logarithms | Exponential (poly‑time vs. sub‑exponential classical) | Quantum Fourier transform on periodicity of modular exponentiation. |\n",
            "| **Grover’s search** (1996) | Unstructured search in N items | Quadratic (O(√N) vs. O(N)) | Amplitude amplification via repeated oracle + diffusion operator. |\n",
            "| **Quantum Phase Estimation** | Eigenvalue estimation, used as sub‑routine | Enables many other algorithms (e.g., Hamiltonian simulation). |\n",
            "| **Variational Quantum Eigensolver (VQE)** | Approximate ground‑state energies of molecules | Polynomial scaling for certain chemistry problems; hybrid quantum‑classical optimisation. |\n",
            "| **Quantum Approximate Optimization Algorithm (QAOA)** | Approximate combinatorial optimisation | Promising for NP‑hard problems; performance still under study. |\n",
            "\n",
            "These algorithms illustrate how **interference** and **entanglement** can be harnessed to solve specific tasks more efficiently than any known classical method.\n",
            "\n",
            "---\n",
            "\n",
            "## 5. Historical Context (Timeline Highlights)\n",
            "\n",
            "* **1980s** – Conceptual foundations (Feynman’s “quantum simulator”, Benioff’s quantum Turing machine).  \n",
            "* **1994** – Peter Shor publishes his factoring algorithm, sparking intense interest.  \n",
            "* **1996** – Lov Grover introduces quantum search.  \n",
            "* **2001** – First experimental demonstration of a 2‑qubit quantum gate (NIST).  \n",
            "* **2011‑2014** – First small‑scale quantum processors (IBM, D‑Wave’s quantum annealer).  \n",
            "* **2019** – Google claims “quant\n",
            "\n",
            "⏱️  Total execution time: 6.20s\n",
            "============================================================\n",
            "\n",
            "Press Enter to continue to next query...quit\n",
            "\n",
            "\n",
            "🔍 TEST QUERY 3\n",
            "\n",
            "============================================================\n",
            "🚀 PARALLEL TOOL-CALLING RAG SYSTEM\n",
            "============================================================\n",
            "🔍 Query: Recent research papers on large language models\n",
            "🛠️  Selected tools: vector_search_tool, web_search_tool, arxiv_search_tool\n",
            "⚡ Executing 3 tools in parallel...\n",
            "✓ vector_search_tool completed in 0.02s\n",
            "✓ arxiv_search_tool completed in 0.61s\n",
            "✓ web_search_tool completed in 10.84s\n",
            "\n",
            "🎯 Parallel execution completed in 10.84s\n",
            "📊 Fused results from 3 successful tools\n",
            "✨ Generated comprehensive answer with 4549 characters of context\n",
            "\n",
            "============================================================\n",
            "📝 FINAL ANSWER\n",
            "============================================================\n",
            "Below is a curated, up‑to‑date (2022‑2024) list of research papers that have shaped the **large language model (LLM)** landscape in the last few years.  The papers are grouped by theme, each entry includes the full citation, venue (or pre‑print server), a short “take‑away” summary, and a link to the PDF or publisher page when available.  Wherever possible the sources you provided (Wikipedia, the arXiv survey, the Nature “Industrial applications of LLMs” article, the Two‑Sigma NeurIPS‑2023 roundup, and the AAAI‑25 tutorial list) are referenced.\n",
            "\n",
            "---\n",
            "\n",
            "## 1️⃣ Foundational/Scale‑Up LLMs (2022‑2024)\n",
            "\n",
            "| Year | Paper (Link) | Authors / Org. | Venue | Core Contribution |\n",
            "|------|--------------|----------------|-------|-------------------|\n",
            "| **2022** | **“Scaling Laws for Neural Language Models”** <br> https://arxiv.org/abs/2001.08361 | Kaplan *et al.* (OpenAI) | *arXiv* | Empirical laws that predict how loss improves with model size, dataset size, and compute – the “scaling law” foundation for GPT‑3‑style models. |\n",
            "| **2022** | **“PaLM: Scaling Language Modeling with Pathways”** <br> https://arxiv.org/abs/2204.02311 | Chowdhery *et al.* (Google) | *arXiv* | 540‑B‑parameter dense transformer that introduced “Pathways” for efficient parallelism; set new few‑shot performance benchmarks. |\n",
            "| **2022** | **“LLaMA: Open and Efficient Foundation Language Models”** <br> https://arxiv.org/abs/2302.13971 | Touvron *et al.* (Meta) | *arXiv* | 7‑B‑to‑65‑B‑parameter models released under a research‑only license; demonstrated that strong performance can be achieved with fewer parameters when trained on high‑quality data. |\n",
            "| **2023** | **“GPT‑4 Technical Report”** <br> https://arxiv.org/abs/2303.08774 | OpenAI | *arXiv* | First public technical description of GPT‑4 (multimodal, 1‑trillion‑parameter scale, improved alignment). |\n",
            "| **2023** | **“Gemini: A Family of Highly Capable Multimodal Models”** <br> https://arxiv.org/abs/2312.11805 | Google DeepMind | *arXiv* | Introduces Gemini‑1 (text‑only) and Gemini‑1.5 (text‑+‑vision) models, highlighting instruction‑tuning, safety‑steering, and multimodal reasoning. |\n",
            "| **2023** | **“A Survey of GPT‑3 Family Large Language Models Including ChatGPT and GPT‑4”** <br> https://arxiv.org/abs/2310.04004 | Katikapalli Subramanyam Kalyan | *arXiv* (Oct 2023) | Comprehensive taxonomy of GPT‑3‑family models, their training regimes, evaluation, and emerging applications. *(source from the arXiv search tool)* |\n",
            "| **2024** | **“LLaMA 2: Open Foundation Language Models”** <br> https://arxiv.org/abs/2307.09288 | Touvron *et al.* (Meta) | *arXiv* | 7‑B, 13‑B, and 70‑B parameter models with instruction‑tuned variants; open‑source weights and RLHF‑style safety finetuning. |\n",
            "| **2024** | **“Mistral‑7B: A 7‑B Parameter Model Trained on 1 Trillion Tokens”** <br> https://arxiv.org/abs/2402.01815 | Mistral AI | *arXiv* | Demonstrates that a 7‑B model can rival 30‑B‑plus models when trained on a high‑quality, curated token stream. |\n",
            "\n",
            "---\n",
            "\n",
            "## 2️⃣ Retrieval‑Augmented Generation (RAG) & Knowledge‑Grounded LLMs  \n",
            "\n",
            "*(The Wikipedia entry on Retrieval‑augmented generation (RAG) gives a high‑level definition; the papers below flesh out the state‑of‑the‑art.)*\n",
            "\n",
            "| Year | Paper (Link) | Authors | Venue | Take‑away |\n",
            "|------|--------------|---------|-------|-----------|\n",
            "| **2022** | **“Retrieval‑Augmented Generation for Knowledge‑Intensive NLP Tasks”** <br> https://arxiv.org/abs/2005.11401 | Lewis *et al.* (Facebook AI) | *ACL 2020 (pre‑print 2022)* | Introduced the **RAG** architecture (retriever + generator) that dramatically improves open‑domain QA and fact‑checking. |\n",
            "| **2023** | **“Atlas: A Large Language Model with Integrated Retrieval”** <br> https://arxiv.org/abs/2309.07597 | Izacard *et al.* (Meta) | *arXiv* | 11‑B‑parameter model that jointly learns retrieval and generation; achieves state‑of‑the‑art on open‑domain QA while keeping inference cheap. |\n",
            "| **2023** | **“Self‑RAG: Self‑Supervised Retrieval‑Augmented Generation”** <br> https://arxiv.org/abs/2305.14223 | Liu *et al.* (Microsoft) | *NeurIPS 2023* | Uses the LLM itself to generate pseudo‑queries for building a retrieval index, removing the need for external annotators. |\n",
            "| **2024** | **“Hybrid Retrieval‑Augmented Generation for Long‑Form Generation”** <br> https://arxiv.org/abs/2403.05678 | Zhou *et al.* (Stanford) | *ICLR 2024* | Combines dense vector retrieval with symbolic knowledge graphs to produce coherent, citation‑rich long‑form answers. |\n",
            "| **2024** | **“Industrial Applications of Large Language Models”** (Scientific Reports) <br> https://www.nature.com/articles/s41598-025-98483-1 | Various (Nature) | *Scientific Reports* (2025) | Survey of >100 papers (2020‑2024) on RAG‑based solutions in finance, healthcare, and manufacturing; highlights practical deployment challenges (source from web search). |\n",
            "\n",
            "---\n",
            "\n",
            "## 3️⃣ Instruction‑Tuning, RLHF, and Alignment  \n",
            "\n",
            "| Year | Paper (Link) | Authors | Venue | Core Idea |\n",
            "|------|--------------|---------|-------|-----------|\n",
            "| **2022** | **“Fine‑Tuning Language Models from Human Preferences”** <br> https://arxiv.org/abs/2203.02155 | Ziegler *et al.* (OpenAI) | *ICLR 2022* | Early RLHF pipeline that aligns GPT‑3‑style models with human feedback. |\n",
            "| **2023** | **“InstructGPT: Improving Language Models by Learning from Human Feedback”** <br> https://arxiv.org/abs/2203.02155 | Ouyang *et al.* (OpenAI) | *arXiv* | Scales RLHF to 175 B‑parameter models; introduces “preference‑based” loss and a “reward model”. |\n",
            "| **2023** | **“ChatGPT: Optimizing Language Models for Dialogue”** (OpenAI blog + technical report) | OpenAI | *arXiv* (2023‑12) | Describes the iterative instruction‑tuning and RLHF loop that produced ChatGPT. |\n",
            "| **2024** | **“SFT‑RLHF: A Unified Framework for Supervised Fine‑Tuning and Reinforcement Learning from Human Feedback”** <br> https://arxiv.org/abs/2401.01845 | Bai *et al.* (DeepMind) | *NeurIPS 2024* | Shows that a single-stage SFT‑RLHF pipeline can match two‑stage pipelines while reducing compute. |\n",
            "| **202\n",
            "\n",
            "⏱️  Total execution time: 15.42s\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_system_stats():\n",
        "    \"\"\"Get system performance statistics.\"\"\"\n",
        "    stats = {\n",
        "        \"vector_db_docs\": vectorstore._collection.count(),\n",
        "        \"available_tools\": [\"web_search\", \"wikipedia\", \"arxiv\", \"vector_search\", \"document_loader\"],\n",
        "        \"parallel_execution\": \"enabled\",\n",
        "        \"intelligent_routing\": \"enabled\"\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "get_system_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7r62CQ3lSNy",
        "outputId": "516bf614-b3a0-4f1b-a327-d7177dce7015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vector_db_docs': 4,\n",
              " 'available_tools': ['web_search',\n",
              "  'wikipedia',\n",
              "  'arxiv',\n",
              "  'vector_search',\n",
              "  'document_loader'],\n",
              " 'parallel_execution': 'enabled',\n",
              " 'intelligent_routing': 'enabled'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ScxW4LZvmI48"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}